{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d51afa0-ba43-4357-8e26-810e7925b5d3",
   "metadata": {},
   "source": [
    "# Link to GITHUB Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f874c63-dae8-4bd2-bd55-40fe37d9bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/zengkaipeng/UAlign"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672ce748-dd1e-4963-ae64-5cb8e57f5c9e",
   "metadata": {},
   "source": [
    "# Modified Graph Util Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e245d8ed-05a9-4a54-b5fe-eef0402aabb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.utils.features import (\n",
    "    allowable_features, atom_to_feature_vector, bond_feature_vector_to_dict,\n",
    "    bond_to_feature_vector, atom_feature_vector_to_dict\n",
    ")\n",
    "import torch\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "\n",
    "def smiles2graph(smiles_string, with_amap=False):\n",
    "    \"\"\"\n",
    "    Converts SMILES string to graph Data object\n",
    "    :input: SMILES string (str)\n",
    "    :return: graph object\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles_string)\n",
    "    if mol is None:\n",
    "        return None \n",
    "\n",
    "    if with_amap:\n",
    "        if len(mol.GetAtoms()) > 0:\n",
    "            max_amap = max([atom.GetAtomMapNum() for atom in mol.GetAtoms()])\n",
    "            for atom in mol.GetAtoms():\n",
    "                if atom.GetAtomMapNum() == 0:\n",
    "                    atom.SetAtomMapNum(max_amap + 1)\n",
    "                    max_amap = max_amap + 1\n",
    "\n",
    "            amap_idx = {\n",
    "                atom.GetAtomMapNum(): atom.GetIdx()\n",
    "                for atom in mol.GetAtoms()\n",
    "            }\n",
    "        else:\n",
    "            amap_idx = dict()\n",
    "\n",
    "\n",
    "    atom_features_list = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        atom_features_list.append(atom_to_feature_vector(atom))\n",
    "\n",
    "    num_atom_features = 9\n",
    "    if len(atom_features_list) > 0:\n",
    "        x = np.array(atom_features_list, dtype=np.int64)\n",
    "    else:\n",
    "        x = np.empty((0, num_atom_features), dtype=np.int64)\n",
    "\n",
    "\n",
    "    num_bond_features = 3 \n",
    "    if len(mol.GetBonds()) > 0: \n",
    "        edges_list = []\n",
    "        edge_features_list = []\n",
    "        for bond in mol.GetBonds():\n",
    "            i = bond.GetBeginAtomIdx()\n",
    "            j = bond.GetEndAtomIdx()\n",
    "\n",
    "            edge_feature = bond_to_feature_vector(bond)\n",
    "\n",
    "            edges_list.append((i, j))\n",
    "            edge_features_list.append(edge_feature)\n",
    "            edges_list.append((j, i))\n",
    "            edge_features_list.append(edge_feature)\n",
    "\n",
    "        edge_index = np.array(edges_list, dtype=np.int64).T\n",
    "\n",
    "        edge_attr = np.array(edge_features_list, dtype=np.int64)\n",
    "\n",
    "    else:\n",
    "        edge_index = np.empty((2, 0), dtype=np.int64)\n",
    "        edge_attr = np.empty((0, num_bond_features), dtype=np.int64)\n",
    "\n",
    "    graph = dict()\n",
    "    graph['edge_index'] = edge_index\n",
    "    graph['edge_feat'] = edge_attr\n",
    "    graph['node_feat'] = x\n",
    "    graph['num_nodes'] = len(x)\n",
    "\n",
    "    if with_amap:\n",
    "        return graph, amap_idx\n",
    "    else:\n",
    "        return graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162c591a-26f9-4124-baf4-e62e9859ccd6",
   "metadata": {},
   "source": [
    "# Modified Inference Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826f171a-7923-4d8c-82f7-735f8c6b4c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(dim=768, n_layer=8, heads=12, negative_slope=0.2, seed=2023, device=0, checkpoint='model.pth', token_ckpt='token.pkl', use_class=False, max_len=100, beams=1, product_smiles='product_smiles_test.csv', input_class=-1, org_output=False, output_file='results.csv')\n",
      "[INFO] Loading model weight in model.pth\n",
      "[INFO] padding index 265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing SMILES:  99%|████████████████████████████████████████████████████████▋| 7648/7690 [1:38:43<00:36,  1.16it/s]"
     ]
    }
   ],
   "source": [
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import argparse\n",
    "import json\n",
    "import pickle\n",
    "from model import PretrainModel, PositionalEncoding\n",
    "from data_utils import fix_seed\n",
    "from torch.nn import TransformerDecoderLayer, TransformerDecoder\n",
    "from sparse_backBone import GATBase\n",
    "from utils.chemistry_parse import clear_map_number, canonical_smiles\n",
    "from utils.graph_utils import smiles2graph\n",
    "import pandas as pd\n",
    "import torch_geometric\n",
    "from inference_tools import beam_search_one\n",
    "import time\n",
    "import os\n",
    "import rdkit\n",
    "from rdkit import RDLogger\n",
    "\n",
    "def make_graph_batch(smi, rxn=None):\n",
    "    graph = smiles2graph(smi, with_amap=False)\n",
    "    if graph is None:\n",
    "        return None\n",
    "\n",
    "    num_nodes = graph['node_feat'].shape[0]\n",
    "    num_edges = graph['edge_index'].shape[1]\n",
    "\n",
    "    data = {\n",
    "        'x': torch.from_numpy(graph['node_feat']),\n",
    "        'num_nodes': num_nodes,\n",
    "        'edge_attr': torch.from_numpy(graph['edge_feat']),\n",
    "        'edge_index': torch.from_numpy(graph['edge_index']),\n",
    "        'ptr': torch.LongTensor([0, num_nodes]),\n",
    "        'e_ptr': torch.LongTensor([0, num_edges]),\n",
    "        'batch': torch.zeros(num_nodes).long(),\n",
    "        'e_batch': torch.zeros(num_edges).long(),\n",
    "        'batch_mask': torch.ones(1, num_nodes).bool()\n",
    "    }\n",
    "\n",
    "    if rxn is not None:\n",
    "        data['node_rxn'] = torch.ones(num_nodes).long() * rxn\n",
    "        data['edge_rxn'] = torch.ones(num_edges).long() * rxn\n",
    "    return torch_geometric.data.Data(**data)\n",
    "\n",
    "args = argparse.Namespace(\n",
    "    dim=768,\n",
    "    n_layer=8,\n",
    "    heads=12,\n",
    "    negative_slope=0.2,\n",
    "    seed=2023,\n",
    "    device=0,\n",
    "    checkpoint='model.pth',\n",
    "    token_ckpt='token.pkl',\n",
    "    use_class=False,\n",
    "    max_len=100,\n",
    "    beams=1,\n",
    "    product_smiles='product_smiles_test.csv',\n",
    "    input_class=-1,\n",
    "    org_output=False,\n",
    "    output_file='results.csv'\n",
    ")\n",
    "\n",
    "print(args)\n",
    "\n",
    "if not torch.cuda.is_available() or args.device < 0:\n",
    "    device = torch.device('cpu')\n",
    "else:\n",
    "    device = torch.device(f'cuda:{args.device}')\n",
    "\n",
    "fix_seed(args.seed)\n",
    "with open(args.token_ckpt, 'rb') as Fin:\n",
    "    tokenizer = pickle.load(Fin)\n",
    "\n",
    "GNN = GATBase(\n",
    "    num_layers=args.n_layer, dropout=0.1, embedding_dim=args.dim,\n",
    "    num_heads=args.heads, negative_slope=args.negative_slope,\n",
    "    n_class=11 if args.use_class else None\n",
    ")\n",
    "\n",
    "decode_layer = TransformerDecoderLayer(\n",
    "    d_model=args.dim, nhead=args.heads, batch_first=True,\n",
    "    dim_feedforward=args.dim * 2, dropout=0.1\n",
    ")\n",
    "Decoder = TransformerDecoder(decode_layer, args.n_layer)\n",
    "Pos_env = PositionalEncoding(args.dim, 0.1, maxlen=2000)\n",
    "\n",
    "model = PretrainModel(\n",
    "    token_size=tokenizer.get_token_size(), encoder=GNN,\n",
    "    decoder=Decoder, d_model=args.dim, pos_enc=Pos_env\n",
    ").to(device)\n",
    "\n",
    "if args.checkpoint != '':\n",
    "    assert args.token_ckpt != '', 'Missing Tokenizer Information'\n",
    "    print(f'[INFO] Loading model weight in {args.checkpoint}')\n",
    "    weight = torch.load(args.checkpoint, map_location=device)\n",
    "    model.load_state_dict(weight, strict=False)\n",
    "\n",
    "print('[INFO] padding index', tokenizer.token2idx['<PAD>'])\n",
    "if args.use_class:\n",
    "    assert args.input_class != -1, 'require reaction class!'\n",
    "    start_token, rxn_class = f'<RXN>_{args.input_class}', args.input_class\n",
    "else:\n",
    "    start_token, rxn_class = '<CLS>', None\n",
    "\n",
    "lg = RDLogger.logger()\n",
    "lg.setLevel(RDLogger.CRITICAL)\n",
    "\n",
    "smiles_df = pd.read_csv(args.product_smiles, header=None)\n",
    "product_smiles_list = smiles_df[0].tolist()\n",
    "\n",
    "results = []\n",
    "for product_smiles in tqdm(product_smiles_list, desc=\"Processing SMILES\"):\n",
    "    prd = canonical_smiles(product_smiles)\n",
    "    g_ip = make_graph_batch(prd, rxn_class)\n",
    "    if g_ip is None:\n",
    "        print(f\"Invalid SMILES string: {product_smiles}\")\n",
    "        results.append([product_smiles, \"\", \"\", args.input_class])\n",
    "        continue\n",
    "    g_ip = g_ip.to(device)\n",
    "\n",
    "    preds, probs = beam_search_one(\n",
    "        model, tokenizer, g_ip, device, max_len=args.max_len,\n",
    "        size=args.beams, begin_token=start_token, end_token='<END>',\n",
    "        pen_para=0, validate=not args.org_output\n",
    "    )\n",
    "\n",
    "    results.append([product_smiles, preds, probs, args.input_class])\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(args.output_file, header=False, index=False)\n",
    "\n",
    "print('[RESULT]')\n",
    "print(json.dumps(results, indent=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c378ff-40dc-4c89-9aeb-5817d607e555",
   "metadata": {},
   "source": [
    "# Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdcdc72-60cb-44a4-95d9-476cf1c2c9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python inference_one.py --dim 768 --n_layer 8 --heads 12 --device 0 --checkpoint model.pth --token_ckpt token.pkl --negative_slope 0.2 --max_len 100 --beams 1 --product_smiles product_smiles_test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec0d327-ee86-4a7a-95bb-53a523d448d6",
   "metadata": {},
   "source": [
    "# Code for Processing Result CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53387064-40e3-4288-8a6f-94184800c062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('results.csv', header=None)\n",
    "\n",
    "second_column = df[1]\n",
    "\n",
    "second_column = second_column.str.strip(\"[]\").str.replace(\"'\", \"\")\n",
    "\n",
    "second_column.to_csv('processed_results.csv', header=False, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
